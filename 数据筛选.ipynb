{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0a1a0c-aa42-49c3-bc4d-6a23248a3320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   事件名称    1000 non-null   object        \n",
      " 1   大事件     1000 non-null   object        \n",
      " 2   事件背景    1000 non-null   object        \n",
      " 3   主关键词    1000 non-null   object        \n",
      " 4   监测起始时间  1000 non-null   datetime64[ns]\n",
      " 5   监测结束时间  1000 non-null   datetime64[ns]\n",
      " 6   首曝时间    1000 non-null   datetime64[ns]\n",
      " 7   地域      1000 non-null   object        \n",
      " 8   倾向      1000 non-null   object        \n",
      " 9   话题领域    1000 non-null   object        \n",
      " 10  涉事主体    1000 non-null   object        \n",
      " 11  风险类型    1000 non-null   object        \n",
      " 12  传播量     1000 non-null   float64       \n",
      "dtypes: datetime64[ns](3), float64(1), object(9)\n",
      "memory usage: 101.7+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r6/npr8y8412_z7wkpbn702g8dm0000gn/T/ipykernel_35489/2258676620.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['大事件'].fillna('未知', inplace=True)  # 填充缺失值\n",
      "/var/folders/r6/npr8y8412_z7wkpbn702g8dm0000gn/T/ipykernel_35489/2258676620.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['风险类型'].fillna('未知', inplace=True)  # 填充缺失值\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '事件筛选2023.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 处理缺失值\n",
    "df['大事件'].fillna('未知', inplace=True)  # 填充缺失值\n",
    "df['风险类型'].fillna('未知', inplace=True)  # 填充缺失值\n",
    "\n",
    "# 确保时间列的数据类型\n",
    "df['监测起始时间'] = pd.to_datetime(df['监测起始时间'], errors='coerce')\n",
    "df['监测结束时间'] = pd.to_datetime(df['监测结束时间'], errors='coerce')\n",
    "df['首曝时间'] = pd.to_datetime(df['首曝时间'], errors='coerce')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddea7981-8510-43ef-860a-34acede888f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "筛选后的Dataset:\n",
      "                         事件名称   大事件  \\\n",
      "999         洪都拉斯寻求与中国正式建立外交关系    未知   \n",
      "998           我国自主研发的新一代CPU发布     　   \n",
      "997            杭州亚运会中国体育代表团成立    未知   \n",
      "996       印度“月船3号”月球探测器着陆月球表面    未知   \n",
      "995     十三届全国人大常委会第三十九次会议在京举行    未知   \n",
      "..                        ...   ...   \n",
      "904  习近平主席出席金砖国家领导人巴以问题特别视频峰会  巴以冲突   \n",
      "903              华为15亿成立房地产公司    未知   \n",
      "902       侯友宜获提名参选2024台湾地区领导人    未知   \n",
      "901           一中国香港籍货轮在长崎近海沉没    未知   \n",
      "900             山西安泽施工事故致7人遇难     　   \n",
      "\n",
      "                                                  事件背景  \\\n",
      "999           3月15日，洪都拉斯总统发文称，已指示外长寻求与中华人民共和国建立正式外交关系。   \n",
      "998  11月28日，2023龙芯产品发布暨用户大会在北京举行。大会发布了新一代通用处理器龙芯3A6...   \n",
      "997  杭州第19届亚运会中国体育代表团成立大会12日在北京举行。出征杭州亚运会的中国体育代表团共有...   \n",
      "996   8月23日新德里消息：印度空间研究组织当地时间23日宣布，“月船3号”月球探测器已着陆月球表面。   \n",
      "995  2月23日上午，十三届全国人大常委会第三十九次会议在北京人民大会堂举行第一次全体会议。经审查...   \n",
      "..                                                 ...   \n",
      "904  11月21日晚，国家主席习近平出席金砖国家领导人巴以问题特别视频峰会并发表题为《推动停火止战...   \n",
      "903  据国家企业信用信息系统显示，8月3日，华为投资控股有限公司出资成立东莞棠雅实业投资有限公司，...   \n",
      "902  据台湾媒体报道，国民党17日召开中常会，党主席朱立伦正式宣布，征召侯友宜参选2024台湾地区...   \n",
      "901  香港东网援引日本媒体25日报道，一艘香港注册货船当日凌晨在长崎县男女群岛附近沉没，船上载有2...   \n",
      "900  24日22时许，安泽县山西永鑫通海铁路物流有限责任公司发生一起施工事故，现场的浇筑通廊混凝土...   \n",
      "\n",
      "                                                  主关键词     监测起始时间     监测结束时间  \\\n",
      "999  洪都拉斯&中国&外交关系\\n洪都拉斯&中方&外交关系\\n洪都拉斯&我国&外交关系\\n洪都拉斯... 2023-03-15 2023-03-22   \n",
      "998  龙芯&上新\\n龙芯&新一代CPU&发布\\n龙芯&新一代通用处理器&发布\\n龙芯&3A6000... 2023-11-28 2023-12-05   \n",
      "997                                       亚运&中国&代表团&成立 2023-09-12 2023-09-19   \n",
      "996                                               月船3号 2023-08-23 2023-08-30   \n",
      "995    十四届&人大代表&2977名\\n新一届&人大代表&2977名\\n十三届&全国人大&三十九次会议 2023-02-23 2023-03-02   \n",
      "..                                                 ...        ...        ...   \n",
      "904  习近平&巴以问题&峰会\\n习近平&金砖国家&巴以\\n习近平&推动停火止战\\n习近平&巴勒斯坦... 2023-11-21 2023-11-28   \n",
      "903                                    华为&房地产\\n任正非&房地产 2023-08-03 2023-08-10   \n",
      "902  侯友宜&领导人&2024\\n侯友宜&领导人&参选\\n侯友宜&领导人&候选人\\n侯友宜&领导人... 2023-05-17 2023-05-24   \n",
      "901  香港&货轮&长崎&沉没\\n香港&货轮&日本&沉没\\n香港&货船&长崎&沉没\\n香港&货船&日... 2023-01-24 2023-01-31   \n",
      "900  山西&被埋&工地&遇难\\n山西&施工事故&遇难\\n山西&永鑫通海&遇难\\n安泽&施工事故&遇... 2023-11-24 2023-12-01   \n",
      "\n",
      "          首曝时间       地域  倾向       话题领域  \\\n",
      "999 2023-03-15       国际  中性       时政外交   \n",
      "998 2023-11-28      北京市  正面       科技创新   \n",
      "997 2023-09-12      北京市  正面       教育文化   \n",
      "996 2023-08-23       国际  正面       科技创新   \n",
      "995 2023-02-23      北京市  中性       时政外交   \n",
      "..         ...      ...  ..        ...   \n",
      "904 2023-11-21       国际  正面  时政外交|军事国防   \n",
      "903 2023-08-03       全国  中性       互联网类   \n",
      "902 2023-05-17      台湾省  中性       时政外交   \n",
      "901 2023-01-24       国际  负面       灾害事故   \n",
      "900 2023-11-24  山西省-临汾市  负面       灾害事故   \n",
      "\n",
      "                                                  涉事主体  风险类型       传播量  \n",
      "999                                                 其他  外部环境  128511.0  \n",
      "998                                                 企业     -  128604.0  \n",
      "997                                     地方职能部门|基层政府|个人     -  128860.0  \n",
      "996                                                 其他     -  128890.0  \n",
      "995                                               中央部委     -  129079.0  \n",
      "..                                                 ...   ...       ...  \n",
      "904                                                领导人     -  150883.0  \n",
      "903                                           互联网公司|企业     -  150916.0  \n",
      "902  地方职能部门|基层政府|个人|高校|中小学|教师群体|学生群体|家长群体|职工群体|军人|交...     -  151006.0  \n",
      "901                                                 企业     -  151653.0  \n",
      "900                                              个人|企业  公共安全  151964.0  \n",
      "\n",
      "[100 rows x 13 columns]\n",
      "多样性 (Diversity): 0.045204898175541006\n",
      "传播量 (Propagation Sum): 557289.56\n",
      "大事件个数: 100\n",
      "话题领域多样性: 0.27450980392156865\n",
      "涉事主体多样性: 0.23577235772357724\n",
      "风险类型多样性: 0.7368421052631579\n",
      "总事件数: 100\n",
      "倾向占比:\n",
      "倾向\n",
      "中性    0.36\n",
      "负面    0.29\n",
      "正面    0.28\n",
      "争议    0.07\n",
      "Name: proportion, dtype: float64\n",
      "筛选后的Dataset已保存为Excel文件： 筛选后的事件组合2023.xlsx\n",
      "多样性 (Diversity): 0.045204898175541006\n",
      "传播量 (Propagation Sum): 557289.56\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 设置传播量上限\n",
    "propagation_min = 70000000\n",
    "propagation_max = 500000000# 根据需要设定\n",
    "\n",
    "def select(population, fitness_scores):\n",
    "        \n",
    "    # 将适应度分数转换为概率分布\n",
    "    fitness_total = sum(fitness_scores)\n",
    "    if fitness_total == 0:\n",
    "        probabilities = np.full(len(population), 1/len(population))\n",
    "    else:\n",
    "        probabilities = [score / fitness_total for score in fitness_scores]\n",
    "    \n",
    "    # 根据概率选择个体\n",
    "    selected_index = np.random.choice(len(population), p=probabilities)\n",
    "    return population[selected_index]\n",
    "    \n",
    "# 计算多样性和均衡性方差的函数\n",
    "def calculate_diversity_and_variance(df, topic_col='话题领域', subject_col='涉事主体', risk_col='风险类型'):\n",
    "    unique_topics_ratio = df[topic_col].nunique() / 102\n",
    "    unique_subjects_ratio = df[subject_col].nunique() / 123\n",
    "    unique_risks_ratio = df[risk_col].nunique() / 19\n",
    "    \n",
    "    diversity = unique_topics_ratio * unique_subjects_ratio * unique_risks_ratio\n",
    "    \n",
    "    std_topics = df[topic_col].value_counts(normalize=True).std()\n",
    "    std_subjects = df[subject_col].value_counts(normalize=True).std()\n",
    "    std_risks = df[risk_col].value_counts(normalize=True).std()\n",
    "    std_spread = df['传播量'].std()\n",
    "    \n",
    "    variance_diversity = std_topics * std_subjects * std_risks * std_spread\n",
    "    \n",
    "    objective = diversity / variance_diversity\n",
    "    \n",
    "    return objective\n",
    "\n",
    "# 评估个体适应度的函数\n",
    "def evaluate(individual, df, propagation_min, propagation_max, topic_col='话题领域', subject_col='涉事主体', risk_col='风险类型'):\n",
    "    selected_events = individual\n",
    "    propagation_sum = (selected_events['传播量'] * 0.4 * 0.1).sum()  # 调整传播量的比例\n",
    "\n",
    "    if propagation_sum < propagation_min or propagation_sum > propagation_max:\n",
    "        return (0, )\n",
    "    \n",
    "    diversity = calculate_diversity_and_variance(selected_events, topic_col, subject_col, risk_col)\n",
    "\n",
    "    # 倾向权重\n",
    "    tendency_weight = selected_events['倾向'].isin(['负面', '争议']).mean()\n",
    "    \n",
    "    # 大事件覆盖率\n",
    "    big_events_count = selected_events['大事件'].notnull().sum()\n",
    "    total_events_count = len(selected_events)\n",
    "    big_events_coverage = big_events_count / total_events_count if total_events_count > 0 else 0\n",
    "    \n",
    "    # 大事件多样性\n",
    "    big_events = selected_events[selected_events['大事件'].notnull()]\n",
    "    big_events_diversity = big_events[topic_col].nunique()\n",
    "\n",
    "    # 综合适应度\n",
    "    fitness = diversity * tendency_weight * big_events_coverage * big_events_diversity\n",
    "    return fitness\n",
    "\n",
    "# 贪心算法生成初始种群，确保不重复选择事件\n",
    "def generate_initial_population(events_df, max_spread, population_size=10):\n",
    "    initial_population = []\n",
    "    \n",
    "    # 根据传播量排序，选择传播量较小的事件优先\n",
    "    sorted_events = events_df.sort_values(by=\"传播量\")\n",
    "    \n",
    "    for _ in range(population_size):\n",
    "        selected_events = []  # 用于存储当前组合中的事件\n",
    "        selected_event_ids = set()  # 用于追踪已选择的事件ID\n",
    "        spread_sum = 0  # 当前组合的传播量和\n",
    "\n",
    "        # 按顺序选择事件，确保不重复选择\n",
    "        for _, event in sorted_events.iterrows():\n",
    "            # 检查事件是否已被选择，且是否满足传播量限制\n",
    "            if event['事件名称'] not in selected_event_ids and spread_sum + event['传播量'] <= propagation_max:\n",
    "                selected_events.append(event)  # 将事件加入组合\n",
    "                selected_event_ids.add(event['事件名称'])  # 记录事件ID，防止重复\n",
    "                spread_sum += event['传播量']  # 更新传播量和\n",
    "\n",
    "                # 确保每个个体包含约100个事件\n",
    "                if len(selected_events) >= 100:\n",
    "                    break\n",
    "        \n",
    "        # 如果事件数量不足100，继续选择直到达到100个\n",
    "        while len(selected_events) < 100 and spread_sum < propagation_max:\n",
    "            for _, event in sorted_events.iterrows():\n",
    "                if event['事件名称'] not in selected_event_ids and spread_sum + event['传播量'] <= propagation_max:\n",
    "                    selected_events.append(event)\n",
    "                    selected_event_ids.add(event['事件名称'])\n",
    "                    spread_sum += event['传播量']\n",
    "                    if len(selected_events) >= 100:\n",
    "                        break\n",
    "        \n",
    "        # 将选择的事件集转化为 DataFrame 并加入初始种群\n",
    "        selected_events_df = pd.DataFrame(selected_events)\n",
    "        \n",
    "        # 去重：确保每个“大事件”只保留一个事件\n",
    "        big_events = selected_events_df[selected_events_df['大事件'].notnull()]\n",
    "        if len(big_events) > 1:\n",
    "            big_events = big_events.drop_duplicates(subset=['事件名称'], keep='first')\n",
    "            selected_events_df = pd.concat([selected_events_df[~selected_events_df['事件名称'].isin(big_events['事件名称'])], big_events])\n",
    "        \n",
    "        # 将选择的事件集转化为DataFrame并加入初始种群\n",
    "        initial_population.append(pd.DataFrame(selected_events_df))\n",
    "\n",
    "    return initial_population\n",
    "\n",
    "# 交叉操作，确保生成的新个体不包含重复事件\n",
    "def crossover(parent1, parent2):\n",
    "    # 随机选择交叉点\n",
    "    cross_point = random.randint(0, len(parent1) - 1)\n",
    "    \n",
    "    # 使用交叉点前后的事件组合创建子代，并去重\n",
    "    child1_events = pd.concat([parent1.iloc[:cross_point], parent2.iloc[cross_point:]]).drop_duplicates(subset='事件名称')\n",
    "    child2_events = pd.concat([parent2.iloc[:cross_point], parent1.iloc[cross_point:]]).drop_duplicates(subset='事件名称')\n",
    "    \n",
    "    # 去重：确保每个“大事件”只保留一个事件\n",
    "    child1_big_events = child1_events[child1_events['大事件'].notnull()]\n",
    "    if len(child1_big_events) > 1:\n",
    "        child1_big_events = child1_big_events.drop_duplicates(subset=['事件名称'], keep='first')\n",
    "        child1_events = pd.concat([child1_events[~child1_events['事件名称'].isin(child1_big_events['事件名称'])], child1_big_events])\n",
    "    \n",
    "    child2_big_events = child2_events[child2_events['大事件'].notnull()]\n",
    "    if len(child2_big_events) > 1:\n",
    "        child2_big_events = child2_big_events.drop_duplicates(subset=['事件名称'], keep='first')\n",
    "        child2_events = pd.concat([child2_events[~child2_events['事件名称'].isin(child2_big_events['事件名称'])], child2_big_events])\n",
    "    \n",
    "    # 返回两个子代\n",
    "    return child1_events, child2_events\n",
    "\n",
    "# 变异操作，确保新的事件不会重复选择\n",
    "def mutate(individual, events_df, mutation_rate=0.1):\n",
    "    selected_event_ids = set(individual['事件名称'])  # 获取当前个体中的事件ID\n",
    "    for i in range(len(individual)):\n",
    "        if random.random() < mutation_rate:\n",
    "            # 从整个事件集随机选择一个未被选择的事件\n",
    "            new_event = events_df[~events_df['事件名称'].isin(selected_event_ids)].sample(1).iloc[0]\n",
    "            individual.iloc[i] = new_event  # 将当前事件替换为新事件\n",
    "            selected_event_ids.add(new_event['事件名称'])  # 更新选定事件的ID集合\n",
    "\n",
    "    # 去重：确保每个“大事件”只保留一个事件\n",
    "    big_events = individual[individual['大事件'].notnull()]\n",
    "    if len(big_events) > 1:\n",
    "        big_events = big_events.drop_duplicates(subset=['事件名称'], keep='first')\n",
    "        individual = pd.concat([individual[~individual['事件名称'].isin(big_events['事件名称'])], big_events])\n",
    "    return individual\n",
    "\n",
    "def elitist_selection(population, fitness_scores, elite_size):\n",
    "    # 将个体与其适应度分数配对\n",
    "    paired_population = list(zip(population, fitness_scores))\n",
    "    # 按适应度分数排序\n",
    "    paired_population.sort(key=lambda x: x[1], reverse=True)\n",
    "    # 选择适应度最高的elite_size个个体\n",
    "    elite_individuals = [individual for individual, score in paired_population[:elite_size]]\n",
    "    return elite_individuals\n",
    "\n",
    "# 遗传算法主函数\n",
    "def genetic_algorithm(events_df, propagation_min, propagation_max, generations=100, population_size=200, mutation_rate=0.1, elite_size = 10):\n",
    "    # 初始种群生成\n",
    "    population = generate_initial_population(events_df, propagation_max, population_size)\n",
    "    \n",
    "    for generation in range(generations):\n",
    "        # 计算每个个体的适应度分数\n",
    "        fitness_scores = [evaluate(individual, events_df, propagation_min, propagation_max) for individual in population]\n",
    "        fitness_scores = [score if isinstance(score, (int, float)) else score[0] for score in fitness_scores]\n",
    "\n",
    "        if len(fitness_scores) != len(population):\n",
    "            raise ValueError(\"Fitness scores length does not match population length\")\n",
    "\n",
    "        # 精英选择策略\n",
    "        elite_individuals = elitist_selection(population, fitness_scores, elite_size)\n",
    "        \n",
    "        new_population = elite_individuals.copy()\n",
    "        \n",
    "        # 生成下一代个体\n",
    "        while len(new_population) < population_size:\n",
    "            # 选择父代\n",
    "            parent1 = select(population, fitness_scores)\n",
    "            parent2 = select(population, fitness_scores)\n",
    "            \n",
    "            # 交叉操作生成子代，并确保去重\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            \n",
    "            # 变异操作，确保事件唯一性\n",
    "            child1 = mutate(child1, events_df, mutation_rate)\n",
    "            child2 = mutate(child2, events_df, mutation_rate)\n",
    "            \n",
    "            new_population.extend([child1, child2])  # 添加新个体至种群\n",
    "        \n",
    "        # 更新种群\n",
    "        population = new_population[:population_size]\n",
    "    \n",
    "    # 找到适应度最高的个体\n",
    "    fitness_scores = [evaluate(individual, events_df, propagation_min, propagation_max) for individual in population]\n",
    "    best_individual = population[fitness_scores.index(max(fitness_scores))]\n",
    "    \n",
    "    return best_individual\n",
    "\n",
    "# 执行遗传算法，输出最优组合\n",
    "best_dataset = genetic_algorithm(df, propagation_min, propagation_max, elite_size = 10)\n",
    "\n",
    "# 计算筛选后的多样性和传播量\n",
    "final_diversity = calculate_diversity_and_variance(best_dataset, topic_col='话题领域', subject_col='涉事主体', risk_col='风险类型')\n",
    "final_propagation_sum = (best_dataset['传播量'] * 0.4 * 0.1).sum()\n",
    "\n",
    "# 计算大事件的个数\n",
    "big_events_count = best_dataset[best_dataset['大事件'].notnull()].shape[0]\n",
    "\n",
    "# 计算三种多样性数值\n",
    "unique_topics_diversity = best_dataset['话题领域'].nunique() / 102\n",
    "unique_subjects_diversity = best_dataset['涉事主体'].nunique() / 123\n",
    "unique_risks_diversity = best_dataset['风险类型'].nunique() / 19\n",
    "\n",
    "# 计算总事件数\n",
    "total_events_count = best_dataset.shape[0]\n",
    "\n",
    "# 计算倾向中各类别的占比\n",
    "tendency_counts = best_dataset['倾向'].value_counts(normalize=True)\n",
    "\n",
    "# 输出筛选后的Dataset及其相关统计信息\n",
    "print(\"筛选后的Dataset:\")\n",
    "print(best_dataset)\n",
    "print(\"多样性 (Diversity):\", final_diversity)\n",
    "print(\"传播量 (Propagation Sum):\", final_propagation_sum)\n",
    "print(\"大事件个数:\", big_events_count)\n",
    "print(\"话题领域多样性:\", unique_topics_diversity)\n",
    "print(\"涉事主体多样性:\", unique_subjects_diversity)\n",
    "print(\"风险类型多样性:\", unique_risks_diversity)\n",
    "print(\"总事件数:\", total_events_count)\n",
    "print(\"倾向占比:\")\n",
    "print(tendency_counts)\n",
    "\n",
    "# 保存筛选后的数据集为 Excel 文件\n",
    "output_file_path = '筛选后的事件组合2023.xlsx'\n",
    "best_dataset.to_excel(output_file_path, index=False)\n",
    "\n",
    "# 输出筛选结果和文件保存路径\n",
    "print(\"筛选后的Dataset已保存为Excel文件：\", output_file_path)\n",
    "print(\"多样性 (Diversity):\", final_diversity)\n",
    "print(\"传播量 (Propagation Sum):\", final_propagation_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12acdc9-3968-4040-8538-7368eb5f7444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
